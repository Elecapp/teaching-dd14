---
title: 8_ What are the recurring words used in relation to the different approaches?
cover: ./assets/images/covers/cover08.png
number: 8
---
### Description
The treemap shows how <strong>recurring words</strong> in the posts analyzed in the previous protocol are <strong>used in relation to the approach</strong> of the post itself. Each rectangle is a word, blue if used on Twitter and red if used on Weibo; the ones with a marked rectangle around them are the ones in common. The size represents how many times a word was written. When each button is clicked, the main recurring related words used in the posts with that type of approach are highlighted. We matched these information to better understand the relation between specific words and the approaches to the theme. We decided to extrapolate words so that we could understand the vocabulary used within every approach and also in <strong>comparison between the two platforms</strong>, so the two cultures. Itâ€™s interesting to see how the word <i>honest</i> is used only by Chinese people, while words like <i>die</i> or <i>orwellian</i> are used only by the western world.

### Protocol

![example of protocol]({{ '/assets/images/protocols/protocol8.svg' | relative_url }})

From the previous protocol, we extracted the recurring words for both Weibo and Twitter, with <i>Wordcounter</i>, <i>Text analyzer</i> and <i>Zhonghuayuwen</i>.
Then, we selected the first 10 recurring words and the most relevant posts for each kind of approach for both western and Chinese social networks. Finally we matched these two information in a treemap made with <i>Raw Graph</i> that we reworked with <i>Illustrator</i>.

### Data
##### Data Source: [Twitter](https://twitter.com/), [Weibo](https://www.weibo.com/)
##### Timestamp: 01/12/2018
##### [View Data (500Kb)](https://www.dropbox.com/sh/1ztygeamxrn2yy2/AAAB-FnVu63G7lrG_R1C87n3a/%238?dl=0)
The file focuses on how many times a word is written and the relation between these words and the approach of the posts in which they were used. For that reason, the dataset is made by two columns: keywords (filtered words) and occurrences.
